import { aiManager, AI_MODELS } from './ai-manager';

interface DeepAnalysisRequest {
  topic: string;
  keywords: string[];
  category?: string;
  saudiContext?: string;
}

interface AIModelResult {
  model: string;
  content: string;
  timestamp: Date;
  tokensUsed?: number;
}

const DEEP_ANALYSIS_GOLDEN_TEMPLATE = `
ุฃูุช ูุญูู ุงุณุชุฑุงุชูุฌู ูุชุฎุตุต ูู ุงูุชุญููู ุงูุนููู ููุฃุญุฏุงุซ ูุงููุถุงูุง ุงููุนุงุตุฑุฉ.
ูููุชู: ุฅูุชุงุฌ ุชุญููู ุดุงูู ููุชุนุฏุฏ ุงูุฃุจุนุงุฏ ููููุถูุน ุงููุญุฏุฏ.

๐ **ุงูุจููุฉ ุงููุทููุจุฉ ููุชุญููู (10 ุฃูุณุงู):**

## 1. ุงูููุฏูุฉ ูุงูุณูุงู ุงูุนุงู
- ุชุนุฑูู ููุฌุฒ ุจุงูููุถูุน
- ุฃูููุฉ ุงูููุถูุน ุงูุขู
- ุงููุทุงู ุงูุฒููู ูุงูููุงูู ููุชุญููู

## 2. ุชุญููู ุงููุถุน ุงูุฑุงูู
- ุงูุญูุงุฆู ุงูุฃุณุงุณูุฉ
- ุงูุฃุทุฑุงู ุงููุนููุฉ
- ุงูุฃุฑูุงู ูุงูุจูุงูุงุช ุงูุฑุฆูุณูุฉ

## 3. ุงูุฌุฐูุฑ ุงูุชุงุฑูุฎูุฉ ูุงูุฎูููุฉ
- ุงูุฃุญุฏุงุซ ุงููุคุฏูุฉ ูููุถุน ุงูุญุงูู
- ุงูุชุทูุฑุงุช ุงูุชุงุฑูุฎูุฉ ุฐุงุช ุงูุตูุฉ
- ุงูุฃููุงุท ุงููุชูุฑุฑุฉ

## 4. ุงูุชุญููู ุงูุงุณุชุฑุงุชูุฌู ูุชุนุฏุฏ ุงูุฃุจุนุงุฏ
- **ุงูุจุนุฏ ุงูุณูุงุณู:** ุงูุชุฃุซูุฑุงุช ูุงูุชุฏุงุนูุงุช ุงูุณูุงุณูุฉ
- **ุงูุจุนุฏ ุงูุงูุชุตุงุฏู:** ุงูุขุซุงุฑ ุงููุงููุฉ ูุงูุชุฌุงุฑูุฉ
- **ุงูุจุนุฏ ุงูุงุฌุชูุงุนู:** ุงูุชุฃุซูุฑ ุนูู ุงููุฌุชูุน ูุงูุฑุฃู ุงูุนุงู
- **ุงูุจุนุฏ ุงูุชููู:** ุงูุฌูุงูุจ ุงูุชูููููุฌูุฉ ูุงูุงุจุชูุงุฑ
- **ุงูุจุนุฏ ุงููุงูููู:** ุงูุฃุทุฑ ุงููุงููููุฉ ูุงูุชูุธูููุฉ

## 5. ุงูุณููุงุฑูููุงุช ุงููุณุชูุจููุฉ
- **ุงูุณููุงุฑูู ุงูุฃูุถู:** ุฃูุถู ุงููุชุงุฆุฌ ุงูููููุฉ
- **ุงูุณููุงุฑูู ุงูุฃุณูุฃ:** ุฃุณูุฃ ุงููุชุงุฆุฌ ุงููุญุชููุฉ
- **ุงูุณููุงุฑูู ุงูุฃุฑุฌุญ:** ุงูุชููุนุงุช ุงููุงูุนูุฉ
- ุงุญุชูุงูุงุช ูู ุณููุงุฑูู

## 6. ุงูุชุฃุซูุฑ ุนูู ุงูููููุฉ ุงูุนุฑุจูุฉ ุงูุณุนูุฏูุฉ
- ุงูุขุซุงุฑ ุงููุจุงุดุฑุฉ ุนูู ุงูุณุนูุฏูุฉ
- ุงููุฑุต ุงูุงุณุชุฑุงุชูุฌูุฉ
- ุงูุชุญุฏูุงุช ูุงููุฎุงุทุฑ
- ุงูุชูุงูู ูุน ุฑุคูุฉ 2030

## 7. ุงูููุงุฑูุงุช ุงูุฏูููุฉ
- ููู ุชุนุงููุช ุฏูู ุฃุฎุฑู ูุน ูุถุงูุง ููุงุซูุฉ
- ุงูุฏุฑูุณ ุงููุณุชูุงุฏุฉ
- ุฃูุถู ุงูููุงุฑุณุงุช ุงูุนุงูููุฉ

## 8. ุชุญููู ุฃุตุญุงุจ ุงููุตูุญุฉ
- ุงููุงุฆุฒูู ูุงูุฎุงุณุฑูู
- ุงููุตุงูุญ ุงููุชุถุงุฑุจุฉ
- ุงูุชุญุงููุงุช ูุงูุตุฑุงุนุงุช ุงููุญุชููุฉ

## 9. ุงูุชูุตูุงุช ุงูุงุณุชุฑุงุชูุฌูุฉ
- ุชูุตูุงุช ูุตูุฑุฉ ุงููุฏู (0-6 ุฃุดูุฑ)
- ุชูุตูุงุช ูุชูุณุทุฉ ุงููุฏู (6-18 ุดูุฑ)
- ุชูุตูุงุช ุทูููุฉ ุงููุฏู (18+ ุดูุฑ)
- ุชูุตูุงุช ุฎุงุตุฉ ุจุตุงูุนู ุงููุฑุงุฑ

## 10. ุงูุฎูุงุตุฉ ูุงูููุงุท ุงูุฑุฆูุณูุฉ
- ุฃูู 5 ููุงุท ูุฌุจ ุชุฐูุฑูุง
- ุงูุฑุณุงูุฉ ุงูุฑุฆูุณูุฉ
- ุงูุฏุนูุฉ ููุนูู

โ๏ธ **ูุนุงููุฑ ุงูุฌูุฏุฉ:**
- ุงูููุถูุนูุฉ ูุงูุญูุงุฏูุฉ
- ุงูุงุนุชูุงุฏ ุนูู ุงูุจูุงูุงุช ูุงูุญูุงุฆู
- ุงูุชุญููู ุงููุชุนูู ูููุณ ุงูุณุทุญู
- ุงููุบุฉ ุงูุนุฑุจูุฉ ุงููุตุญู ุงููุงุถุญุฉ
- ุงูุงุณุชุดูุงุฏ ุจุงููุตุงุฏุฑ ุนูุฏ ุงูุฅููุงู
- ุชุฌูุจ ุงูุชุนูููุงุช ูุงูุขุฑุงุก ุงูุดุฎุตูุฉ

๐ **ุงููุฎุฑุฌ ุงููุทููุจ:**
ุชุญููู ุดุงูู ุจุตูุบุฉ Markdown ูุบุทู ุฌููุน ุงูุฃูุณุงู ุงูุนุดุฑุฉ ุจุนูู ูุชูุตูู.
`;

export class DeepAnalysisEngine {
  async generateAnalysis(request: DeepAnalysisRequest): Promise<{
    gpt5Result?: AIModelResult;
    geminiResult?: AIModelResult;
    claudeResult?: AIModelResult;
    unifiedAnalysis: string;
    executiveSummary: string;
    recommendations: string[];
  }> {
    const userPrompt = this.buildUserPrompt(request);
    const fullPrompt = `${DEEP_ANALYSIS_GOLDEN_TEMPLATE}\n\n${userPrompt}`;
    
    const configs = [
      { ...AI_MODELS.GPT5, maxTokens: 16000 },
      { ...AI_MODELS.CLAUDE_SONNET, temperature: 0.7, maxTokens: 16000 },
      { ...AI_MODELS.GEMINI_FLASH, temperature: 0.7, maxTokens: 16000 },
    ];

    const results = await aiManager.generateMultiple(fullPrompt, configs);

    const gpt5Result: AIModelResult | undefined = results[0] && !results[0].error ? {
      model: results[0].model,
      content: results[0].content,
      timestamp: new Date(),
      tokensUsed: results[0].usage ? results[0].usage.inputTokens + results[0].usage.outputTokens : undefined,
    } : undefined;

    const claudeResult: AIModelResult | undefined = results[1] && !results[1].error ? {
      model: results[1].model,
      content: results[1].content,
      timestamp: new Date(),
      tokensUsed: results[1].usage ? results[1].usage.inputTokens + results[1].usage.outputTokens : undefined,
    } : undefined;

    const geminiResult: AIModelResult | undefined = results[2] && !results[2].error ? {
      model: results[2].model,
      content: results[2].content,
      timestamp: new Date(),
      tokensUsed: results[2].usage ? results[2].usage.inputTokens + results[2].usage.outputTokens : undefined,
    } : undefined;

    const unifiedAnalysis = await this.synthesizeAnalyses({
      gpt5: gpt5Result?.content,
      claude: claudeResult?.content,
      gemini: geminiResult?.content,
    });

    const executiveSummary = await this.generateExecutiveSummary(unifiedAnalysis);
    const recommendations = await this.extractRecommendations(unifiedAnalysis);

    return {
      gpt5Result,
      geminiResult,
      claudeResult,
      unifiedAnalysis,
      executiveSummary,
      recommendations,
    };
  }

  private buildUserPrompt(request: DeepAnalysisRequest): string {
    let prompt = `## ุงูููุถูุน ุงููุทููุจ ุชุญูููู:\n${request.topic}\n\n`;
    
    if (request.keywords && request.keywords.length > 0) {
      prompt += `## ุงููููุงุช ุงูููุชุงุญูุฉ:\n${request.keywords.join('ุ ')}\n\n`;
    }
    
    if (request.category) {
      prompt += `## ุงูุชุตููู:\n${request.category}\n\n`;
    }
    
    if (request.saudiContext) {
      prompt += `## ุงูุณูุงู ุงูุณุนูุฏู ุงูุฅุถุงูู:\n${request.saudiContext}\n\n`;
    }
    
    prompt += `\nูุฑุฌู ุฅูุชุงุฌ ุชุญููู ุดุงูู ูุบุทู ุฌููุน ุงูุฃูุณุงู ุงูุนุดุฑุฉ ุงููุทููุจุฉ ุจุนูู ูุชูุตูู.`;
    
    return prompt;
  }

  private async synthesizeAnalyses(analyses: {
    gpt5?: string;
    claude?: string;
    gemini?: string;
  }): Promise<string> {
    const availableAnalyses = Object.entries(analyses)
      .filter(([_, content]) => content)
      .map(([model, content]) => ({ model, content }));

    if (availableAnalyses.length === 0) {
      throw new Error('No analyses available to synthesize');
    }

    if (availableAnalyses.length === 1) {
      return availableAnalyses[0].content!;
    }
    
    const synthesisPrompt = `
ุฃูุช ูุญูู ุฎุจูุฑ. ูุฏูู ${availableAnalyses.length} ุชุญูููุงุช ุนูููุฉ ูู ููุงุฐุฌ AI ูุฎุชููุฉ ุญูู ููุณ ุงูููุถูุน.
ูููุชู: ุฏูุฌ ูุฐู ุงูุชุญูููุงุช ูู ุชุญููู ููุญุฏ ุดุงูู ูุฌูุน ุฃูุถู ูุง ูู ูู ุชุญููู.

${availableAnalyses.map((a, i) => `
### ุงูุชุญููู ${i + 1} (ูู ูููุฐุฌ ${a.model}):
${a.content}
`).join('\n\n')}

## ุงููุทููุจ:
ูู ุจุฅูุชุงุฌ ุชุญููู ููุญุฏ ูุงุญุฏ ูุฌูุน:
- ุงูููุงุท ุงููุดุชุฑูุฉ ุจูู ุงูุชุญูููุงุช
- ุงูููุงุท ุงููุฑูุฏุฉ ูู ูู ุชุญููู
- ุญู ุงูุชูุงูุถุงุช ุจุทุฑููุฉ ููุทููุฉ
- ุงูุญูุงุธ ุนูู ุงูุจููุฉ ุงูุฐูุจูุฉ ุงูููููุฉ ูู 10 ุฃูุณุงู

ูุฌุจ ุฃู ูููู ุงูุชุญููู ุงูููุญุฏ ุฃูุถู ูู ุฃู ุชุญููู ูุฑุฏู.
`;

    const result = await aiManager.generate(
      synthesisPrompt,
      { ...AI_MODELS.CLAUDE_SONNET, temperature: 0.5, maxTokens: 16000 }
    );

    return result.content;
  }

  private async generateExecutiveSummary(analysis: string): Promise<string> {
    const summaryPrompt = `
ูู ุจุฅูุชุงุฌ ููุฎุต ุชูููุฐู (Executive Summary) ูุฎุชุตุฑ ููุชุญููู ุงูุชุงูู.

ุงูุชุญููู ุงููุงูู:
${analysis}

## ุงููุทููุจ:
ููุฎุต ุชูููุฐู ูู 150-200 ูููุฉ ูุบุทู:
1. ุงูููุถูุน ุงูุฑุฆูุณู
2. ุงููุชุงุฆุฌ ุงูุฃุณุงุณูุฉ
3. ุงูุชูุตูุงุช ุงูุฃูู
4. ุงูุฑุณุงูุฉ ุงูุฑุฆูุณูุฉ

ุงูููุฎุต ููุฌู ูุตุงูุนู ุงููุฑุงุฑ ุงูุฐูู ูุง ูููููู ููุชุงู ููุฑุงุกุฉ ุงูุชุญููู ูุงููุงู.
`;

    const result = await aiManager.generate(
      summaryPrompt,
      { ...AI_MODELS.CLAUDE_SONNET, temperature: 0.3, maxTokens: 500 }
    );

    return result.content;
  }

  private async extractRecommendations(analysis: string): Promise<string[]> {
    const extractPrompt = `
ุงุณุชุฎุฑุฌ ุฌููุน ุงูุชูุตูุงุช ูู ุงูุชุญููู ุงูุชุงููุ ูุฑุชุจูุง ุญุณุจ ุงูุฃููููุฉ.

ุงูุชุญููู:
${analysis}

## ุงููุทููุจ:
ูุงุฆูุฉ ุจุงูุชูุตูุงุช ุงูุงุณุชุฑุงุชูุฌูุฉ (5-10 ุชูุตูุงุช)ุ ูู ูุงุญุฏุฉ ูู ุณุทุฑ ูุงุญุฏ.
ูุฏู ูู ุชูุตูุฉ ูููุทุฉ ูุงุถุญุฉ ูุงุจูุฉ ููุชูููุฐ.

ุตูุบุฉ ุงูุฅุฎุฑุงุฌ:
- ุชูุตูุฉ 1
- ุชูุตูุฉ 2
- ุชูุตูุฉ 3
...
`;

    const result = await aiManager.generate(
      extractPrompt,
      { ...AI_MODELS.CLAUDE_SONNET, temperature: 0.2, maxTokens: 1000 }
    );

    const recommendations = result.content
      .split('\n')
      .filter((line: string) => line.trim().startsWith('-'))
      .map((line: string) => line.trim().substring(1).trim())
      .filter((rec: string) => rec.length > 0);

    return recommendations;
  }

  async generateQuickAnalysis(
    topic: string,
    model: 'openai' | 'anthropic' | 'gemini' = 'anthropic'
  ): Promise<AIModelResult> {
    const userPrompt = this.buildUserPrompt({ topic, keywords: [] });
    const fullPrompt = `${DEEP_ANALYSIS_GOLDEN_TEMPLATE}\n\n${userPrompt}`;
    
    const modelConfig = model === 'openai' ? AI_MODELS.GPT5 
      : model === 'gemini' ? AI_MODELS.GEMINI_FLASH 
      : AI_MODELS.CLAUDE_SONNET;

    const configWithSettings = model === 'openai' 
      ? { ...modelConfig, maxTokens: 16000 }
      : { ...modelConfig, temperature: 0.7, maxTokens: 16000 };

    const result = await aiManager.generate(
      fullPrompt,
      configWithSettings
    );

    return {
      model: result.model,
      content: result.content,
      timestamp: new Date(),
      tokensUsed: result.usage ? result.usage.inputTokens + result.usage.outputTokens : undefined,
    };
  }
}

export const deepAnalysisEngine = new DeepAnalysisEngine();
